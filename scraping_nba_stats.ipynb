{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQiXT3TmLhlk"
      },
      "source": [
        "Probably isn't the cleanest code or makes use of the best coding methods.\n",
        "\n",
        "source: https://www.basketball-reference.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hXAjdATb6Qz"
      },
      "source": [
        "# Read in and Create data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BbbId4W73jog"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FclwZnZs3n71"
      },
      "outputs": [],
      "source": [
        "# for loop getting required webpages\n",
        "years = range(1950,2023)\n",
        "\n",
        "frames = {}\n",
        "df = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Yigit Cevik\\AppData\\Local\\Temp\\ipykernel_15268\\2370855118.py:10: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  year_data = pd.read_html(str(table))[0]\n"
          ]
        }
      ],
      "source": [
        "for y in years:        # NBA season to scrape\n",
        "  year = y\n",
        "  # URL to scrape, notice f string:\n",
        "  frames[\"url\" + str(y)] = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_game.html\"\n",
        "  response = requests.get(frames[\"url\" + str(y)])\n",
        "  if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    table = soup.find('table', {'id': 'per_game_stats'})  # Finding the right table\n",
        "    if table:\n",
        "      year_data = pd.read_html(str(table))[0]\n",
        "      year_data = year_data[year_data[\"Rk\"] != \"Rk\"]  # Drop unnecessary columns\n",
        "      year_data[\"Year\"] = year\n",
        "      df.append(year_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Concatenate all dataframes\n",
        "final_df = pd.concat(df, ignore_index=True)\n",
        "\n",
        "# Save to CSV\n",
        "final_df.to_csv('archive/nba_stats_1950_2022.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
